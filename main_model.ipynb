{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from prettytable import PrettyTable\n",
    "from torchtext import data\n",
    "import torchtext\n",
    "from torchtext.data import Field,LabelField\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as f\n",
    "from prettytable import PrettyTable\n",
    "import logging\n",
    "import copy\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "class Timer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.running = True\n",
    "        self.total = 0\n",
    "        self.start = time.time()\n",
    "\n",
    "    def reset(self):\n",
    "        self.running = True\n",
    "        self.total = 0\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def resume(self):\n",
    "        if not self.running:\n",
    "            self.running = True\n",
    "            self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def stop(self):\n",
    "        if self.running:\n",
    "            self.running = False\n",
    "            self.total += time.time() - self.start\n",
    "        return self\n",
    "\n",
    "    def time(self):\n",
    "        if self.running:\n",
    "            return self.total + time.time() - self.start\n",
    "        return self.total\n",
    "\n",
    "class Ranker(object):\n",
    "    \n",
    "    def __init__(self,src_dict, unk=\"<UNK>\", embedding_dim=128, hidden_dim=64):\n",
    "        self.src_dict = src_dict\n",
    "        self.unk = unk\n",
    "        self.word_to_ix = src_dict\n",
    "        self.updates = 0\n",
    "\n",
    "        self.network = DSSMModel(\n",
    "                        embedding_dim = embedding_dim,\n",
    "                        hidden_dim = hidden_dim,\n",
    "                        vocab_size = len(self.word_to_ix),\n",
    "                        tagset_size = 128\n",
    "        )\n",
    "        self.criterion = self.compute_loss\n",
    "        \n",
    "    @staticmethod\n",
    "    def compute_loss(predictions, target):\n",
    "        predictions = f.log_softmax(predictions, dim=-1)\n",
    "        loss = -(predictions * target).sum(1)\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "    def layer_wise_parameters(self):\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [\"Layer Name\", \"Output Shape\", \"Param #\"]\n",
    "        table.align[\"Layer Name\"] = \"l\"\n",
    "        table.align[\"Output Shape\"] = \"r\"\n",
    "        table.align[\"Param #\"] = \"r\"\n",
    "        for name, parameters in self.network.named_parameters():\n",
    "            if parameters.requires_grad:\n",
    "                table.add_row([name, str(list(parameters.shape)), parameters.numel()])\n",
    "        return table\n",
    "\n",
    "#     def load_embeddings\n",
    "\n",
    "    def init_optimizer(self, state_dict=None, fix_embeddings=False,\n",
    "                      learning_rate = 0.001, momentum=0, weight_decay=0):\n",
    "        \n",
    "        if fix_embeddings:\n",
    "            for p in self.network.word_embeddings.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        parameters = [p for p in self.network.parameters() if p.requires_grad]\n",
    "        \n",
    "        \n",
    "        self.optimizer = optim.SGD(parameters, learning_rate,\n",
    "                                   momentum=momentum,\n",
    "                                   weight_decay=weight_decay)\n",
    "        \n",
    "\n",
    "        if state_dict is not None:\n",
    "            self.optimizer.load_state_dict(state_dict)\n",
    "            for state in self.optimizer.state.values():\n",
    "                for k, v in state.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        state[k] = v.to(device)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Learning\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    def update(self, rows, grad_clipping = 10):\n",
    "        \"\"\"Forward a batch of examples; step the optimizer to update weights.\"\"\"\n",
    "        if not self.optimizer:\n",
    "            raise RuntimeError('No optimizer set.')\n",
    "        # Train mode\n",
    "        self.network.train()\n",
    "        queries = rows[0] #makeEmbeddingTensors(rows[0],self.word_to_ix,self.unk)\n",
    "        documents = rows[1] #makeEmbeddingTensors(rows[1],self.word_to_ix,self.unk)\n",
    "        \n",
    "        que_len = 0#ex['que_len']\n",
    "        doc_len = 0#ex['doc_len']\n",
    "        \n",
    "        labels = rows[2] #torch.tensor(rows[2], dtype=torch.long).to(device)\n",
    "        \n",
    "\n",
    "        # Run forward\n",
    "        scores = self.network(queries, documents)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        # Clear gradients and run backward\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        torch.nn.utils.clip_grad_norm(self.network.parameters(),\n",
    "                                      grad_clipping)\n",
    "\n",
    "        # Update parameters\n",
    "        self.optimizer.step()\n",
    "        self.updates += 1\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Prediction\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    def predict(self, ex):\n",
    "        \n",
    "        # Eval mode\n",
    "        self.network.eval()\n",
    "\n",
    "        documents = ex['doc_rep']\n",
    "        queries = ex['que_rep']\n",
    "        que_len = ex['que_len']\n",
    "        doc_len = ex['doc_len']\n",
    "        \n",
    "        #CUDAACUDAACUDAACUDAACUDAACUDAACUDAACUDAACUDAACUDAA\n",
    "\n",
    "        # Run forward\n",
    "        scores = self.network(queries, que_len, documents, doc_len)\n",
    "        scores = f.softmax(scores, dim=-1)\n",
    "\n",
    "        return scores\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Saving and loading\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    def save(self, filename):\n",
    "        \n",
    "        network = self.network\n",
    "        state_dict = copy.copy(network.state_dict())\n",
    "        if 'fixed_embedding' in state_dict:\n",
    "            state_dict.pop('fixed_embedding')\n",
    "        params = {\n",
    "            'state_dict': state_dict,\n",
    "            'src_dict': self.src_dict,\n",
    "#             'arags': self.arags,\n",
    "        }\n",
    "        try:\n",
    "            torch.save(params, filename)\n",
    "        except BaseException:\n",
    "            logger.warning('WARN: Saving failed... continuing anyway.')\n",
    "\n",
    "    def checkpoint(self, filename, epoch):\n",
    "        network = self.network\n",
    "        params = {\n",
    "            'state_dict': network.state_dict(),\n",
    "            'src_dict': self.src_dict,\n",
    "#             'arags': self.arags,\n",
    "            'epoch': epoch,\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }\n",
    "        try:\n",
    "            torch.save(params, filename)\n",
    "        except BaseException:\n",
    "            print('WARN: Saving failed... continuing anyway.')\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        logger.info('Loading model %s' % filename)\n",
    "        saved_params = torch.load(\n",
    "            filename, map_location=lambda storage, loc: storage\n",
    "        )\n",
    "        src_dict = saved_params['src_dict']\n",
    "        state_dict = saved_params['state_dict']\n",
    "#         arags = saved_params['arags']\n",
    "#         if new_arags:\n",
    "#             arags = override_model_arags(arags, new_arags)\n",
    "        return Ranker(src_dict, state_dict)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(filename):\n",
    "        logger.info('Loading model %s' % filename)\n",
    "        saved_params = torch.load(\n",
    "            filename, map_location=lambda storage, loc: storage\n",
    "        )\n",
    "        src_dict = saved_params['src_dict']\n",
    "        state_dict = saved_params['state_dict']\n",
    "        epoch = saved_params['epoch']\n",
    "        optimizer = saved_params['optimizer']\n",
    "#         arags = saved_params['arags']\n",
    "        model = Ranker(src_dict, state_dict)\n",
    "        model.init_optimizer(optimizer)\n",
    "        return model, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, dropout=0.5):\n",
    "        super(DSSMModel, self).__init__()\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=1).to(device)\n",
    "        \n",
    "        \n",
    "        self.dropout_embedding = nn.Dropout(p=dropout).to(device)\n",
    "\n",
    "        self.mlp_search_query = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, tagset_size),\n",
    "            nn.Tanh()\n",
    "        ).to(device)\n",
    "        \n",
    "        self.mlp_details = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, tagset_size),\n",
    "            nn.Tanh()\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, batch_queries, batch_docs):\n",
    "        BATCH_SIZE = 1\n",
    "        \n",
    "        batch_queries = batch_queries.reshape(BATCH_SIZE,batch_queries.shape[0])\n",
    "        batch_docs = batch_docs.reshape(BATCH_SIZE,batch_docs.shape[0],batch_docs.shape[1])\n",
    "        \n",
    "        assert batch_queries.shape[0] == batch_docs.shape[0]\n",
    "        \n",
    "        batch_size = batch_queries.shape[0]\n",
    "        qlen = batch_queries.shape[1]\n",
    "        num_docs, dlen = batch_docs.shape[1], batch_docs.shape[2]\n",
    "\n",
    "        # embed query\n",
    "        embedded_queries = self.word_embeddings(batch_queries.unsqueeze(2))\n",
    "        embedded_queries = self.dropout_embedding(embedded_queries)\n",
    "        embedded_queries = embedded_queries.max(1)[0]  # max-pooling\n",
    "\n",
    "        # embed document\n",
    "        doc_rep = batch_docs.view(batch_size * num_docs, dlen).unsqueeze(2)\n",
    "        embedded_docs = self.word_embeddings(doc_rep)\n",
    "        embedded_docs = self.dropout_embedding(embedded_docs)\n",
    "        embedded_docs = embedded_docs.max(1)[0]  # max-pooling\n",
    "        embedded_docs = embedded_docs.view(batch_size, num_docs, -1)\n",
    "\n",
    "        query_rep = self.mlp_search_query(embedded_queries)\n",
    "        doc_rep = self.mlp_details(embedded_docs)\n",
    "#         query_rep = query_rep.unsqueeze(1).expand(*doc_rep.size())\n",
    "        scores = f.cosine_similarity(query_rep, doc_rep, dim=2)\n",
    "\n",
    "        return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_itr, epochs=10, batch_size=32, \n",
    "             data_workers=5,lr_decay=0.95):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        ce_loss = AverageMeter()\n",
    "        epoch_time = Timer()\n",
    "        \n",
    "        model.optimizer.param_groups[0]['lr'] = \\\n",
    "        model.optimizer.param_groups[0]['lr'] * lr_decay\n",
    "\n",
    "#         pbar = tqdm(train_itr)\n",
    "#         pbar.set_description(\"%s\" % 'Epoch = %d [ce_loss = x.xx]' % i)\n",
    "        \n",
    "        for idx,rows in tqdm(enumerate(train_itr)):\n",
    "            net_loss = model.update(rows)\n",
    "            ce_loss.update(net_loss.item(), 1)\n",
    "\n",
    "            log_info = 'Epoch = %d [ce_loss = %.2f]' % \\\n",
    "                       (i, ce_loss.avg)\n",
    "\n",
    "#             pbar.set_description(\"%s\" % log_info)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Checkpoint\n",
    "        model.checkpoint('ranker.pt' + '.checkpoint', i + 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Train Data...')\n",
    "main_data = pd.read_csv('data/train_dssm2.csv')\n",
    "\n",
    "src_dict = makeVocabDict(main_data,['product_title','search_term','brand','product_description'])\n",
    "tabData = makeTensorData(main_data,src_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ranker(src_dict)\n",
    "model.init_optimizer()\n",
    "\n",
    "train(model,tabData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
